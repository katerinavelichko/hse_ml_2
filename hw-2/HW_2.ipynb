{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "3ae1d865-3ce1-485d-8d34-b0b2274c06e8",
      "metadata": {
        "id": "3ae1d865-3ce1-485d-8d34-b0b2274c06e8"
      },
      "source": [
        "# Общие указания\n",
        "\n",
        "Аналогично ДЗ 1\n",
        "\n",
        "каждое задание - 2 балла, доп задания - 1 балл. Всего 9 - потом приводится к 10."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "d64dec9a",
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import time\n",
        "import pandas as pd\n",
        "import networkx as nx\n",
        "from grakel import graph_from_networkx\n",
        "from grakel.kernels import ShortestPath, GraphletSampling, WeisfeilerLehman, NeighborhoodHash, PyramidMatch, OddSth, CoreFramework,  Propagation, RandomWalk, SvmTheta, VertexHistogram\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
        "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
        "from sklearn.datasets import load_iris, load_wine, load_breast_cancer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.neighbors import KernelDensity\n",
        "from sklearn.metrics.pairwise import pairwise_distances\n",
        "from scipy.optimize import minimize\n",
        "import random\n",
        "from types import SimpleNamespace\n",
        "from ucimlrepo import fetch_ucirepo \n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.gaussian_process import GaussianProcessRegressor\n",
        "from sklearn.gaussian_process.kernels import RBF, ConstantKernel, Matern\n",
        "from scipy.stats import norm\n",
        "\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "034feb9c-3e42-49dd-a569-a16b8226d4be",
      "metadata": {
        "id": "034feb9c-3e42-49dd-a569-a16b8226d4be"
      },
      "source": [
        "# Задание 1.\n",
        "\n",
        "Реализуйте непараметрический LDA (лекция 2, слайд 36). Возьмите датасеты из предыдущего ДЗ (3 задание) (если не делали - подберите или сгенерируйте) и попытайтесь побить затюненный регулеризованный LDA (если не делали предыдущее задание или ваша реализация получилась неудачной, то можете взять реализацию из sklearn) подбирая kernel (перебирайте популярные, а также попробуйте придумать свой kernel), lambda (можно подбирать константу, а можно - функцию, лекция 2 - слайд 26). Сравните время работы алгоритмов.\n",
        "\n",
        "**Дополнительно**: реализуйте также local likelihood logistic regression (слайды 27 и 33 из второй лекции в помощь) и сравните с моделями из основной части."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5672fc18",
      "metadata": {},
      "source": [
        "Возьмем RDA из прошлого дз"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "fae1a009",
      "metadata": {},
      "outputs": [],
      "source": [
        "class RegularizedLDA:\n",
        "    def __init__(self):\n",
        "        self.class_covariances = None\n",
        "        self.class_covariances_inv = None\n",
        "        self.discriminant_constants = None\n",
        "        self.class_means = None\n",
        "        self.class_probabilities = None\n",
        "        self.num_classes = None\n",
        "\n",
        "    def fit(self, X, y, alpha=0.5, gamma=0.1):\n",
        "        classes = np.unique(y)\n",
        "        n_samples, n_features = X.shape\n",
        "        class_counts = {cl: np.sum(y == cl) for cl in classes}\n",
        "        n_classes = np.array(list(class_counts.values()))\n",
        "\n",
        "        # вероятности классов (π_k) \n",
        "        self.class_probabilities = n_classes / n_samples\n",
        "\n",
        "        self.num_classes = len(classes)\n",
        "        self.class_means = np.array([X[y == cl].mean(axis=0) for cl in classes]) # средние значения для каждого класса\n",
        "        global_covariance = np.cov(X, rowvar=False)   # общая ковариационная матрица\n",
        "        global_covariance = gamma * global_covariance + (1 - gamma) * np.std(X, axis=0)[:, None] * np.eye(n_features)  # регуляризация ков-й матрицы\n",
        "\n",
        "        # ковариации внутри классов с регуляризацией\n",
        "        self.class_covariances = []\n",
        "        self.class_covariances_inv = []\n",
        "        for cl in classes:\n",
        "            class_cov = np.cov(X[y == cl], rowvar=False)\n",
        "            regularized_cov = alpha * class_cov + (1 - alpha) * global_covariance\n",
        "            self.class_covariances.append(regularized_cov)\n",
        "            self.class_covariances_inv.append(np.linalg.inv(regularized_cov))\n",
        "\n",
        "       \n",
        "        self.discriminant_constants = [\n",
        "            (-0.5 * np.sum(np.log(np.linalg.eigvals(self.class_covariances[i])))+ np.log(self.class_probabilities[i]))\n",
        "            for i in range(self.num_classes)\n",
        "        ]  # конст дискриминантных функций (для каждого класса)\n",
        "\n",
        "    def predict(self, X):\n",
        "        discriminants = np.zeros((X.shape[0], self.num_classes))\n",
        "        for i in range(self.num_classes):\n",
        "            diff = X - self.class_means[i]  # разность между объектом и средним для каждого класса\n",
        "            #  дискриминантная функция для каждого класса\n",
        "            discriminants[:, i] = np.sum(diff @ self.class_covariances_inv[i] * diff, axis=1)\n",
        "            discriminants[:, i] = -0.5 * discriminants[:, i] + self.discriminant_constants[i]\n",
        "\n",
        "        return np.argmax(discriminants, axis=1)\n",
        "\n",
        "    def accuracy(self, X_test, y_test):\n",
        "        y_pred = self.predict(X_test)\n",
        "        return np.mean(y_pred == y_test)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3bcdbb6b",
      "metadata": {},
      "source": [
        "### Реализуем класс - непараметрический LDA с ядрами, доступными KernelDensity и попробуем добавить несколько кастомных"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "2f867611",
      "metadata": {},
      "outputs": [],
      "source": [
        "class NonParametricLDA:\n",
        "    def __init__(self, bandwidth=1.0, kernel='gaussian'):\n",
        "        self.bandwidth = bandwidth\n",
        "        self.class_kdes = None  # ядерные плотностные оценки для каждого класса\n",
        "        self.kernel = kernel\n",
        "        self.class_probabilities = None  # вероятности классов\n",
        "        self.num_classes = None  # количество классов\n",
        "        self.custom_kernels = {\n",
        "            'custom': self._custom_kernel,\n",
        "            'logg': self._log_kernel,  # логарифмическое ядро\n",
        "            'custom2': self._custom2_kernel,  # гиперболическое ядро\n",
        "            'sigmoid': self._sigmoid_kernel  \n",
        "        }\n",
        "    \n",
        "\n",
        "    def fit(self, X, y):\n",
        "        classes = np.unique(y)\n",
        "        n_samples, n_features = X.shape\n",
        "        class_counts = {cl: np.sum(y == cl) for cl in classes}\n",
        "\n",
        "        self.class_probabilities = np.array([class_counts[cl] / n_samples for cl in classes])  # вероятности классов\n",
        "        self.num_classes = len(classes)\n",
        "\n",
        "        # ядерные плотностные модели для каждого класса\n",
        "        self.class_kdes = {}\n",
        "        for cl in classes:\n",
        "            X_class = X[y == cl]\n",
        "            kde = self._fit_kde(X_class)\n",
        "            self.class_kdes[cl] = kde\n",
        "\n",
        "    def predict(self, X):\n",
        "        log_densities = np.zeros((X.shape[0], self.num_classes))\n",
        "        for i, cl in enumerate(self.class_kdes.keys()):\n",
        "            kde = self.class_kdes[cl]\n",
        "            # получаем плотности для каждого объекта \n",
        "            log_densities[:, i] = kde(X) \n",
        "\n",
        "        log_densities += np.log(self.class_probabilities)\n",
        "        return np.argmax(log_densities, axis=1)  # класс с наибольшей вероятностью\n",
        "\n",
        "    def accuracy(self, X_test, y_test):\n",
        "        y_pred = self.predict(X_test)\n",
        "        return np.mean(y_pred == y_test)\n",
        "\n",
        "    def _fit_kde(self, X_class):\n",
        "        # если ядро доступно KernelDensity\n",
        "        if self.kernel in ['gaussian', 'tophat', 'epanechnikov', 'exponential', 'linear', 'cosine']:\n",
        "            def kdee(X):\n",
        "                kde = KernelDensity(kernel=self.kernel, bandwidth=self.bandwidth)\n",
        "                kde.fit(X_class)\n",
        "                return kde.score_samples(X)\n",
        "            return kdee\n",
        "        # если кастомное ядро\n",
        "        else:\n",
        "            def kde_(X):\n",
        "                dist = pairwise_distances(X, X_class, metric='euclidean')\n",
        "                kernel_values = self.custom_kernels[self.kernel](dist, self.bandwidth)\n",
        "                return np.sum(kernel_values, axis=1) / len(X_class)\n",
        "            return kde_\n",
        "\n",
        "    def _custom_kernel(self, dist, bandwidth):\n",
        "        return np.cos(dist / (2 * bandwidth)) * (dist <= bandwidth)\n",
        "    \n",
        "    def _log_kernel(self, dist, bandwidth):\n",
        "        return np.log(1 + dist / bandwidth) * (dist <= bandwidth)\n",
        "    \n",
        "    def _custom2_kernel(self, dist, bandwidth):\n",
        "        return 1 / (dist / bandwidth) ** 2 + 1\n",
        "\n",
        "    def _sigmoid_kernel(self, dist, bandwidth):\n",
        "        return np.tanh(dist / bandwidth)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3e88d8ab",
      "metadata": {},
      "source": [
        "Загрузим датасеты из прошлого дз"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "c7c83472",
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_scale():\n",
        "    df = pd.read_csv(\"https://archive.ics.uci.edu/static/public/12/data.csv\")\n",
        "    dataset = {}\n",
        "    dataset['data'] = df.drop(columns='class')  \n",
        "    dataset['target'] = df['class']  \n",
        "    label_encoder = LabelEncoder()\n",
        "    dataset['target'] = label_encoder.fit_transform(dataset['target'])\n",
        "\n",
        "    return dataset\n",
        "\n",
        "def load_seeds():\n",
        "    url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00236/seeds_dataset.txt\"\n",
        "    df = pd.read_csv(url, sep=\"\\\\t+\", header=None)\n",
        "    \n",
        "    return df\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "48bee87d",
      "metadata": {},
      "source": [
        "### Посмотрим, какой алгоритм работает быстрее и у какого выше accuracy\n",
        "\n",
        "LDA возьмем и из прошлого дз, и из sklearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "6446fd96",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Dataset</th>\n",
              "      <th>Best RDA accuracy</th>\n",
              "      <th>Best RDA Alpha</th>\n",
              "      <th>Best RDA Gamma</th>\n",
              "      <th>Best Logistic Regression accuracy</th>\n",
              "      <th>Best Logistic Regression C</th>\n",
              "      <th>LDA (sklearn) accuracy</th>\n",
              "      <th>Best Nonparametric LDA accuracy</th>\n",
              "      <th>Best Nonparametric LDA Kernel</th>\n",
              "      <th>Best Nonparam LDA Bandwidth (lamda)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>iris</td>\n",
              "      <td>0.933333</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.933333</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.933333</td>\n",
              "      <td>0.933333</td>\n",
              "      <td>tophat</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>wine</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.01</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.1</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>gaussian</td>\n",
              "      <td>0.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>breast_cancer</td>\n",
              "      <td>0.964912</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.973684</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.973684</td>\n",
              "      <td>0.964912</td>\n",
              "      <td>gaussian</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>seeds</td>\n",
              "      <td>0.952381</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.952381</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.928571</td>\n",
              "      <td>0.976190</td>\n",
              "      <td>gaussian</td>\n",
              "      <td>0.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>balance_scale</td>\n",
              "      <td>0.912000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.912000</td>\n",
              "      <td>100.0</td>\n",
              "      <td>0.880000</td>\n",
              "      <td>0.896000</td>\n",
              "      <td>gaussian</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         Dataset  Best RDA accuracy  Best RDA Alpha  Best RDA Gamma  \\\n",
              "0           iris           0.933333             1.0            0.01   \n",
              "1           wine           1.000000             1.0            0.01   \n",
              "2  breast_cancer           0.964912             0.5            0.01   \n",
              "3          seeds           0.952381             0.1            0.01   \n",
              "4  balance_scale           0.912000             1.0            0.01   \n",
              "\n",
              "   Best Logistic Regression accuracy  Best Logistic Regression C  \\\n",
              "0                           0.933333                        10.0   \n",
              "1                           1.000000                         0.1   \n",
              "2                           0.973684                         1.0   \n",
              "3                           0.952381                        10.0   \n",
              "4                           0.912000                       100.0   \n",
              "\n",
              "   LDA (sklearn) accuracy  Best Nonparametric LDA accuracy  \\\n",
              "0                0.933333                         0.933333   \n",
              "1                1.000000                         1.000000   \n",
              "2                0.973684                         0.964912   \n",
              "3                0.928571                         0.976190   \n",
              "4                0.880000                         0.896000   \n",
              "\n",
              "  Best Nonparametric LDA Kernel  Best Nonparam LDA Bandwidth (lamda)  \n",
              "0                        tophat                                  1.0  \n",
              "1                      gaussian                                  0.1  \n",
              "2                      gaussian                                  1.0  \n",
              "3                      gaussian                                  0.1  \n",
              "4                      gaussian                                  1.0  "
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# список датасетов UCI \n",
        "datasets = {\n",
        "    'iris': load_iris(),\n",
        "    'wine': load_wine(),\n",
        "    'breast_cancer': load_breast_cancer(),\n",
        "    'seeds': load_seeds(),\n",
        "    \"balance_scale\": load_scale(),\n",
        "\n",
        "}\n",
        "\n",
        "\n",
        "def compare_rda_logreg():\n",
        "    results = []\n",
        "    time_results = []\n",
        "\n",
        "    for dataset_name, dataset in datasets.items():\n",
        "        if isinstance(dataset, dict):\n",
        "            X = dataset['data']\n",
        "            y = dataset['target']\n",
        "        else:\n",
        "            X = dataset.iloc[:, :-1].values\n",
        "            y = dataset.iloc[:, -1].values - 1\n",
        "        \n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=5)\n",
        "\n",
        "        scaler = StandardScaler()  # стандартизируем данные\n",
        "        X_train_scaled = scaler.fit_transform(X_train)\n",
        "        X_test_scaled = scaler.transform(X_test)\n",
        "        \n",
        "        start_time = time.time()\n",
        "        param_grid_rda = {\n",
        "            'alpha': [0.1, 0.5, 1.0],\n",
        "            'gamma': [0.01, 0.1, 0.5, 1.0]\n",
        "        }\n",
        "        best_rda_sc = 0\n",
        "        best_rda_params = None\n",
        "        \n",
        "        # попробуем разные значения гиперпараметров alpha и gamma для RDA\n",
        "        for alpha in param_grid_rda['alpha']:\n",
        "            for gamma in param_grid_rda['gamma']:\n",
        "                rda_model = RegularizedLDA()\n",
        "                rda_model.fit(X_train_scaled, y_train, alpha=alpha, gamma=gamma)\n",
        "                rda_sc = rda_model.accuracy(X_test_scaled, y_test)\n",
        "                \n",
        "                if rda_sc > best_rda_sc:\n",
        "                    best_rda_sc = rda_sc\n",
        "                    best_rda_params = {'alpha': alpha, 'gamma': gamma}\n",
        "        rda_time = time.time() - start_time\n",
        "        \n",
        "\n",
        "        #подбираем параметры для log reg\n",
        "        start_time = time.time()\n",
        "        param_grid_lr = {'C': [0.01, 0.1, 1, 10, 100]} \n",
        "        lr_model = LogisticRegression(max_iter=10000)\n",
        "        grid_search_lr = GridSearchCV(lr_model, param_grid_lr, cv=5, n_jobs=-1)\n",
        "        grid_search_lr.fit(X_train_scaled, y_train)\n",
        "        lr_best_model = grid_search_lr.best_estimator_\n",
        "        lr_score = lr_best_model.score(X_test_scaled, y_test)\n",
        "        lr_time = time.time() - start_time\n",
        "        \n",
        "        # подбираем ядро и лямбду для NonParametricLDA \n",
        "        start_time = time.time()\n",
        "        kernels = ['gaussian', 'tophat', 'epanechnikov', 'exponential', 'linear', 'cosine', 'custom', 'logg', 'custom2', 'sigmoid' ]\n",
        "        bandwidth = [0.1, 0.5, 1.0, 2.0]  # лямбды (для ширины)\n",
        "        \n",
        "        best_nlda_score = 0\n",
        "        best_kernel = None\n",
        "        best_bandwidth = 1.0\n",
        "        \n",
        "        for kernel in kernels:\n",
        "            for b in bandwidth:\n",
        "                n_model = NonParametricLDA(kernel=kernel, bandwidth=b)\n",
        "                n_model.fit(X_train_scaled, y_train)\n",
        "                score = n_model.accuracy(X_test_scaled, y_test)\n",
        "                # print(kernel,score)\n",
        "                if score > best_nlda_score:\n",
        "                    best_nlda_score = score\n",
        "                    best_kernel = kernel\n",
        "                    best_bandwidth = b\n",
        "        nlda_time = time.time() - start_time\n",
        "\n",
        "    \n",
        "        \n",
        "        # LDA из sklearn\n",
        "        start_time = time.time()\n",
        "        param_grid_rda_sklearn = {'shrinkage': ['auto', 0.1, 0.5, 1.0]}  # регуляризация с shrinkage\n",
        "        rda_sklearn_model = LDA(solver='eigen')\n",
        "        grid_search_rda = GridSearchCV(rda_sklearn_model, param_grid_rda_sklearn, cv=5, n_jobs=-1)\n",
        "        grid_search_rda.fit(X_train_scaled, y_train)\n",
        "        rda_sklearn_best_model = grid_search_rda.best_estimator_\n",
        "        rda_sklearn_score = rda_sklearn_best_model.score(X_test_scaled, y_test)\n",
        "        rda_sklearn_time = time.time() - start_time\n",
        "\n",
        "\n",
        "        results.append({\n",
        "            'Dataset': dataset_name,\n",
        "            'Best RDA accuracy': best_rda_sc,\n",
        "            'Best RDA Alpha': best_rda_params['alpha'],\n",
        "            'Best RDA Gamma': best_rda_params['gamma'],\n",
        "            'Best Logistic Regression accuracy': lr_score,\n",
        "            'Best Logistic Regression C': grid_search_lr.best_params_['C'],\n",
        "            'LDA (sklearn) accuracy': rda_sklearn_score,\n",
        "            'Best Nonparametric LDA accuracy': best_nlda_score,\n",
        "            'Best Nonparametric LDA Kernel': best_kernel,\n",
        "            'Best Nonparam LDA Bandwidth (lamda)': best_bandwidth,\n",
        "        })\n",
        "        time_results.append({\n",
        "            'Dataset': dataset_name,\n",
        "            'RDA time': rda_time,\n",
        "            'Logistic Regression time': lr_time,\n",
        "            'Nonparametric LDA time': nlda_time,\n",
        "            'LDA (sklearn) time': rda_sklearn_time,\n",
        "        })\n",
        "\n",
        "   \n",
        "    df_res = pd.DataFrame(results)\n",
        "    df_time = pd.DataFrame(time_results)\n",
        "    \n",
        "    return df_res, df_time\n",
        "\n",
        "results_df, time_df = compare_rda_logreg()\n",
        "results_df\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "68ba5013",
      "metadata": {},
      "source": [
        " - На большинстве датасетов все модели, показывают хорошую точность\n",
        " - В датасете \"wine\"  все методы достигают 100% точности (может указывать на относительную простоту задачи для выбранных классификаторов), на \"iris\"  все методы достигают 93% точности \n",
        " - В некоторых случаях RDA уступает в точности Logistic Regression и LDA. Например, на \"breast_cancer\" точность RDA составляет 96.49%, тогда как Logistic Regression и LDA достигают 97.37%. На \"seeds\" точность RDA ниже точности Nonparametric LDA (но на \"balance_scale\" точность RDA выше точности Nonparametric LDA ).\n",
        " \n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "5b3f9fdb",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Dataset</th>\n",
              "      <th>RDA time</th>\n",
              "      <th>Logistic Regression time</th>\n",
              "      <th>Nonparametric LDA time</th>\n",
              "      <th>LDA (sklearn) time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>iris</td>\n",
              "      <td>0.017347</td>\n",
              "      <td>0.955469</td>\n",
              "      <td>0.019546</td>\n",
              "      <td>0.028530</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>wine</td>\n",
              "      <td>0.018518</td>\n",
              "      <td>0.050628</td>\n",
              "      <td>0.020353</td>\n",
              "      <td>0.035660</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>breast_cancer</td>\n",
              "      <td>0.035210</td>\n",
              "      <td>0.152933</td>\n",
              "      <td>0.126083</td>\n",
              "      <td>0.098787</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>seeds</td>\n",
              "      <td>0.006652</td>\n",
              "      <td>0.042592</td>\n",
              "      <td>0.018643</td>\n",
              "      <td>0.021502</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>balance_scale</td>\n",
              "      <td>0.003567</td>\n",
              "      <td>0.031609</td>\n",
              "      <td>0.060223</td>\n",
              "      <td>0.029641</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         Dataset  RDA time  Logistic Regression time  Nonparametric LDA time  \\\n",
              "0           iris  0.017347                  0.955469                0.019546   \n",
              "1           wine  0.018518                  0.050628                0.020353   \n",
              "2  breast_cancer  0.035210                  0.152933                0.126083   \n",
              "3          seeds  0.006652                  0.042592                0.018643   \n",
              "4  balance_scale  0.003567                  0.031609                0.060223   \n",
              "\n",
              "   LDA (sklearn) time  \n",
              "0            0.028530  \n",
              "1            0.035660  \n",
              "2            0.098787  \n",
              "3            0.021502  \n",
              "4            0.029641  "
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "time_df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f008fc75",
      "metadata": {},
      "source": [
        "\n",
        "**Получаем, что logistic Regression и\tNonparametric LDA (и то, и то с подбором параметров) работает дольше, чем rda и lda из sklearn**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eec41724",
      "metadata": {},
      "source": [
        "## Дополнительно\n",
        "- реализуйте также local likelihood logistic regression (слайды 27 и 33 из второй лекции в помощь) и сравните с моделями из основной части."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "a1dfd321",
      "metadata": {},
      "outputs": [],
      "source": [
        "class LLLR:\n",
        "    def __init__(self, bandwidth=1.0, kernel='gaussian'):\n",
        "        self.bandwidth = bandwidth\n",
        "        self.kernel = kernel\n",
        "        self.kernels = {\n",
        "            'gaussian': self._gaussian_kernel,\n",
        "            'epanechnikov': self._epanechnikov_kernel,\n",
        "            'tophat': self._tophat_kernel\n",
        "        }\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.X_train = X\n",
        "        self.y_train = y\n",
        "        self.scaler = StandardScaler()\n",
        "        self.X_train_scaled = self.scaler.fit_transform(X)\n",
        "    \n",
        "    def predict(self, X):\n",
        "        X_scaled = self.scaler.transform(X)\n",
        "        predictions = []\n",
        "        \n",
        "        for x_0 in X_scaled: # для каждого х считаем вес и предсказываем класс\n",
        "            weights = self._compute_kernel_weights(x_0)  # веса для ядра\n",
        "            model = LogisticRegression(solver='lbfgs', multi_class='ovr', max_iter=10000)\n",
        "            model.fit(self.X_train_scaled, self.y_train, sample_weight=weights)  #лог рег с учетом весов \n",
        "            predictions.append(model.predict(x_0.reshape(1, -1))[0])        \n",
        "        return np.array(predictions)\n",
        "\n",
        "    def _compute_kernel_weights(self, x_0):\n",
        "        # считаем веса для ядра для одного объекта x_0 \n",
        "        dist = pairwise_distances(self.X_train_scaled , [x_0], metric='euclidean').flatten()\n",
        "        kernel_values = self.kernels[self.kernel](dist, self.bandwidth)\n",
        "        return kernel_values\n",
        "\n",
        "    def _gaussian_kernel(self, dist, bandwidth):\n",
        "        return np.exp(-dist**2 / (2 * bandwidth**2))\n",
        "\n",
        "    def _epanechnikov_kernel(self, dist, bandwidth):\n",
        "        return 3/4 * (1 - (dist / bandwidth)**2) * (np.abs(dist) <= bandwidth)\n",
        "\n",
        "    def _tophat_kernel(self, dist, bandwidth):\n",
        "        return (np.abs(dist) <= bandwidth).astype(float)\n",
        "\n",
        "    def accuracy(self, X, y):\n",
        "        y_pred = self.predict(X)\n",
        "        return np.mean(y_pred == y)\n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "86dd681e",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Dataset</th>\n",
              "      <th>LLLR accuracy</th>\n",
              "      <th>Best LLLR Bandwidth (lamda)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>iris</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>wine</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>breast_cancer</td>\n",
              "      <td>0.973684</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>seeds</td>\n",
              "      <td>0.976190</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>balance_scale</td>\n",
              "      <td>0.896000</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         Dataset  LLLR accuracy  Best LLLR Bandwidth (lamda)\n",
              "0           iris       0.900000                          0.5\n",
              "1           wine       1.000000                          1.0\n",
              "2  breast_cancer       0.973684                          2.0\n",
              "3          seeds       0.976190                          0.5\n",
              "4  balance_scale       0.896000                          1.0"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def evaluate_lllr():\n",
        "    datasets = {\n",
        "        'iris': load_iris(),\n",
        "        'wine': load_wine(),\n",
        "        'breast_cancer': load_breast_cancer(),\n",
        "        'seeds':load_seeds(),\n",
        "        'balance_scale': load_scale(),\n",
        "    }\n",
        "\n",
        "    results = []\n",
        "    time_results = []\n",
        "   \n",
        "    for dataset_name, dataset in datasets.items():\n",
        "        if isinstance(dataset, dict):\n",
        "            X = dataset['data']\n",
        "            y = dataset['target']\n",
        "        else:\n",
        "            X = dataset.iloc[:, :-1].values\n",
        "            y = dataset.iloc[:, -1].values - 1\n",
        "            \n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=5)\n",
        "        \n",
        "        start_time = time.time()\n",
        "        \n",
        "        bandwidth = [0.1, 0.5, 1.0, 2.0]\n",
        "        best_llr_acc = 0\n",
        "        best_bandwidth = 1.0\n",
        "        for b in bandwidth:\n",
        "            model = LLLR(bandwidth=b, kernel='gaussian')\n",
        "            model.fit(X_train, y_train)\n",
        "            acc = model.accuracy(X_test, y_test)\n",
        "            if acc > best_llr_acc:\n",
        "                best_llr_acc = acc\n",
        "                best_bandwidth = b\n",
        "                \n",
        "        lllr_time = time.time() - start_time\n",
        "        \n",
        "        results.append({\n",
        "            'Dataset': dataset_name,\n",
        "            'LLLR accuracy': acc,\n",
        "            'Best LLLR Bandwidth (lamda)': best_bandwidth,\n",
        "            \n",
        "           \n",
        "        })\n",
        "        time_results.append({\n",
        "            'Dataset': dataset_name,\n",
        "            'LLLR time': lllr_time\n",
        "        })\n",
        "        \n",
        "    results_df = pd.DataFrame(results)\n",
        "    time_df = pd.DataFrame(time_results)\n",
        "    \n",
        "    return results_df, time_df\n",
        "\n",
        "results_lllr, time_results_lllr = evaluate_lllr()\n",
        "results_lllr\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "93d52715",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Dataset</th>\n",
              "      <th>Best RDA accuracy</th>\n",
              "      <th>Best RDA Alpha</th>\n",
              "      <th>Best RDA Gamma</th>\n",
              "      <th>Best Logistic Regression accuracy</th>\n",
              "      <th>Best Logistic Regression C</th>\n",
              "      <th>LDA (sklearn) accuracy</th>\n",
              "      <th>Best Nonparametric LDA accuracy</th>\n",
              "      <th>Best Nonparametric LDA Kernel</th>\n",
              "      <th>Best Nonparam LDA Bandwidth (lamda)</th>\n",
              "      <th>LLLR accuracy</th>\n",
              "      <th>Best LLLR Bandwidth (lamda)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>iris</td>\n",
              "      <td>0.933333</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.933333</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.933333</td>\n",
              "      <td>0.933333</td>\n",
              "      <td>tophat</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>wine</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.01</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.1</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>gaussian</td>\n",
              "      <td>0.1</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>breast_cancer</td>\n",
              "      <td>0.964912</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.973684</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.973684</td>\n",
              "      <td>0.964912</td>\n",
              "      <td>gaussian</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.973684</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>seeds</td>\n",
              "      <td>0.952381</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.952381</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.928571</td>\n",
              "      <td>0.976190</td>\n",
              "      <td>gaussian</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.976190</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>balance_scale</td>\n",
              "      <td>0.912000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.912000</td>\n",
              "      <td>100.0</td>\n",
              "      <td>0.880000</td>\n",
              "      <td>0.896000</td>\n",
              "      <td>gaussian</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.896000</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         Dataset  Best RDA accuracy  Best RDA Alpha  Best RDA Gamma  \\\n",
              "0           iris           0.933333             1.0            0.01   \n",
              "1           wine           1.000000             1.0            0.01   \n",
              "2  breast_cancer           0.964912             0.5            0.01   \n",
              "3          seeds           0.952381             0.1            0.01   \n",
              "4  balance_scale           0.912000             1.0            0.01   \n",
              "\n",
              "   Best Logistic Regression accuracy  Best Logistic Regression C  \\\n",
              "0                           0.933333                        10.0   \n",
              "1                           1.000000                         0.1   \n",
              "2                           0.973684                         1.0   \n",
              "3                           0.952381                        10.0   \n",
              "4                           0.912000                       100.0   \n",
              "\n",
              "   LDA (sklearn) accuracy  Best Nonparametric LDA accuracy  \\\n",
              "0                0.933333                         0.933333   \n",
              "1                1.000000                         1.000000   \n",
              "2                0.973684                         0.964912   \n",
              "3                0.928571                         0.976190   \n",
              "4                0.880000                         0.896000   \n",
              "\n",
              "  Best Nonparametric LDA Kernel  Best Nonparam LDA Bandwidth (lamda)  \\\n",
              "0                        tophat                                  1.0   \n",
              "1                      gaussian                                  0.1   \n",
              "2                      gaussian                                  1.0   \n",
              "3                      gaussian                                  0.1   \n",
              "4                      gaussian                                  1.0   \n",
              "\n",
              "   LLLR accuracy  Best LLLR Bandwidth (lamda)  \n",
              "0       0.900000                          0.5  \n",
              "1       1.000000                          1.0  \n",
              "2       0.973684                          2.0  \n",
              "3       0.976190                          0.5  \n",
              "4       0.896000                          1.0  "
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pd.merge(results_df, results_lllr, on='Dataset', how='outer')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "63f232b3",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Dataset</th>\n",
              "      <th>RDA time</th>\n",
              "      <th>Logistic Regression time</th>\n",
              "      <th>Nonparametric LDA time</th>\n",
              "      <th>LDA (sklearn) time</th>\n",
              "      <th>LLLR time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>iris</td>\n",
              "      <td>0.017347</td>\n",
              "      <td>0.955469</td>\n",
              "      <td>0.019546</td>\n",
              "      <td>0.028530</td>\n",
              "      <td>0.260669</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>wine</td>\n",
              "      <td>0.018518</td>\n",
              "      <td>0.050628</td>\n",
              "      <td>0.020353</td>\n",
              "      <td>0.035660</td>\n",
              "      <td>0.217797</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>breast_cancer</td>\n",
              "      <td>0.035210</td>\n",
              "      <td>0.152933</td>\n",
              "      <td>0.126083</td>\n",
              "      <td>0.098787</td>\n",
              "      <td>2.412582</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>seeds</td>\n",
              "      <td>0.006652</td>\n",
              "      <td>0.042592</td>\n",
              "      <td>0.018643</td>\n",
              "      <td>0.021502</td>\n",
              "      <td>0.478018</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>balance_scale</td>\n",
              "      <td>0.003567</td>\n",
              "      <td>0.031609</td>\n",
              "      <td>0.060223</td>\n",
              "      <td>0.029641</td>\n",
              "      <td>0.755712</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         Dataset  RDA time  Logistic Regression time  Nonparametric LDA time  \\\n",
              "0           iris  0.017347                  0.955469                0.019546   \n",
              "1           wine  0.018518                  0.050628                0.020353   \n",
              "2  breast_cancer  0.035210                  0.152933                0.126083   \n",
              "3          seeds  0.006652                  0.042592                0.018643   \n",
              "4  balance_scale  0.003567                  0.031609                0.060223   \n",
              "\n",
              "   LDA (sklearn) time  LLLR time  \n",
              "0            0.028530   0.260669  \n",
              "1            0.035660   0.217797  \n",
              "2            0.098787   2.412582  \n",
              "3            0.021502   0.478018  \n",
              "4            0.029641   0.755712  "
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pd.merge(time_df, time_results_lllr, on='Dataset', how='outer')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7cf02758",
      "metadata": {},
      "source": [
        "Получаем, что LLLR работает в среднем (с подбором лямбды) дольше, чем остальные алгоритмы, и результаты:\n",
        "- на 3/5 датасетов есть алгоритм с таким же результатом (и этот результат-лучший) (wine,breast_cancer,seeds)\n",
        "- на остальных 2/5 существует алгоритм с результатом лучше"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "615cb4e4-1b91-479b-a894-9f2e48ded066",
      "metadata": {
        "id": "615cb4e4-1b91-479b-a894-9f2e48ded066"
      },
      "source": [
        "# Задание 2.\n",
        "\n",
        "Используйте kernel trick для классификации графов с помощью ridge регрессии (она используется для регрессии, но здесь мы сделаем вид, что все ок и будем обрубать значения меньше 0 и больше 1) и svm (в Sklearn можно использовать кастомные kernels).\n",
        "\n",
        "Датасеты отсюда: https://github.com/FilippoMB/Benchmark_dataset_for_graph_classification\n",
        "\n",
        "Ядра можно взять отсюда: https://github.com/ysig/GraKeL\n",
        "\n",
        "Подберите лучшее ядро для всех случаев.\n",
        "\n",
        "**Дополнительно**: поэкспериментируйте с kernel construction на основе kernels из библиотеки и попробуйте предложить свой kernel, который работает лучше"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "b59cd3c8",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['CoreFramework', 'EdgeHistogram', 'GraphHopper', 'GraphletSampling', 'HadamardCode', 'Kernel', 'LovaszTheta', 'MultiscaleLaplacian', 'NeighborhoodHash', 'NeighborhoodSubgraphPairwiseDistance', 'OddSth', 'Propagation', 'PropagationAttr', 'PyramidMatch', 'RandomWalk', 'RandomWalkLabeled', 'ShortestPath', 'ShortestPathAttr', 'SubgraphMatching', 'SvmTheta', 'VertexHistogram', 'WeisfeilerLehman', 'WeisfeilerLehmanOptimalAssignment', '__all__', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__path__', '__spec__', '_c_functions', '_isomorphism', 'core_framework', 'edge_histogram', 'graph_hopper', 'graphlet_sampling', 'hadamard_code', 'kernel', 'lovasz_theta', 'multiscale_laplacian', 'neighborhood_hash', 'neighborhood_subgraph_pairwise_distance', 'odd_sth', 'propagation', 'pyramid_match', 'random_walk', 'shortest_path', 'subgraph_matching', 'svm_theta', 'vertex_histogram', 'weisfeiler_lehman', 'weisfeiler_lehman_optimal_assignment']\n"
          ]
        }
      ],
      "source": [
        "import  grakel.kernels\n",
        "print(dir(grakel.kernels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "a5f75518",
      "metadata": {},
      "outputs": [],
      "source": [
        "np.random.seed(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "dab508fd",
      "metadata": {},
      "outputs": [],
      "source": [
        "# конвертируем графы в формат nx\n",
        "def create_networkx_graph(A, X):\n",
        "    G = nx.from_numpy_array(A)\n",
        "    x_tuple = tuple(map(tuple, X))\n",
        "    nx.set_node_attributes(G, dict(enumerate(x_tuple)), 'features')\n",
        "    return G"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "946d581b",
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_datasets_with_graphs(dataset_name): # options: {easy_small, easy, hard_small, hard}\n",
        "    # dataset_name = \"hard_small\" \n",
        "    loaded = np.load(f'datasets/{dataset_name}.npz', allow_pickle=True)\n",
        "\n",
        "    A_train = list(loaded['tr_adj'])  # матрицы смежности для обучающей выборки\n",
        "    X_train = loaded['tr_feat']  # признаки узлов для обучающей выборки\n",
        "    y_train = loaded['tr_class']  # классы для обучающей выборки\n",
        "    # с test аналогично\n",
        "    A_test = list(loaded['te_adj'])  \n",
        "    X_test = loaded['te_feat']  \n",
        "    y_test = loaded['te_class']  \n",
        "    return A_train, X_train, y_train, A_test, X_test, y_test"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "23eef55d",
      "metadata": {},
      "source": [
        "Смотреть на accuracy будем в виде процентов (accuracy*100) для наглядности"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "1e66b9d0",
      "metadata": {},
      "outputs": [],
      "source": [
        "def kernel_trick_(dataset_name):\n",
        "    A_train, X_train, y_train, A_test, X_test, y_test  = load_datasets_with_graphs(dataset_name)\n",
        "    # графы для обучающей и тестовой выборки\n",
        "    G_tr = [create_networkx_graph(a, x) for a, x in zip(A_train, X_train)]\n",
        "    G_te = [create_networkx_graph(a, x) for a, x in zip(A_test, X_test)]\n",
        "\n",
        "    G_train = list(graph_from_networkx(G_tr, node_labels_tag='features'))\n",
        "    G_test = list(graph_from_networkx(G_te, node_labels_tag='features'))\n",
        "\n",
        "    # нужно преобразовать метки классов, тк сейчаас это не одномерный массив\n",
        "    y_train = np.argmax(y_train, axis=-1)\n",
        "    y_test = np.argmax(y_test, axis=-1)\n",
        "\n",
        "\n",
        "    kernels = [\n",
        "        ShortestPath(normalize=True),\n",
        "        GraphletSampling(k=5, normalize=True), \n",
        "        WeisfeilerLehman(n_iter=5, normalize=True), \n",
        "        NeighborhoodHash(random_state=10, normalize=True), \n",
        "        # NeighborhoodHash(random_state=12, normalize=True), \n",
        "        PyramidMatch(normalize=True), \n",
        "        OddSth(normalize=True), \n",
        "        CoreFramework(normalize=True),\n",
        "        Propagation(random_state=12, normalize=True), \n",
        "        RandomWalk(normalize=True), \n",
        "        SvmTheta(normalize=True), \n",
        "        VertexHistogram(normalize=True)\n",
        "    ]\n",
        "    results = []\n",
        "\n",
        "    for gk in kernels:\n",
        "        \n",
        "        start = time.time()\n",
        "        \n",
        "        K_train = gk.fit_transform(G_train)\n",
        "        K_test = gk.transform(G_test)\n",
        "        \n",
        "        K_train = np.nan_to_num(K_train, nan=0.5)\n",
        "        K_test = np.nan_to_num(K_test, nan=0.5)\n",
        "        \n",
        "        clf_svm = SVC(kernel='precomputed', C=1)\n",
        "        clf_svm.fit(K_train, y_train)\n",
        "        y_pred_svm = clf_svm.predict(K_test)\n",
        "        acc_svm = accuracy_score(y_test, y_pred_svm)\n",
        "        \n",
        "        \n",
        "        y_train_binary = (y_train == 1).astype(int)  # преобразуем метки в бинарные для Ridge\n",
        "        y_test_binary = (y_test == 1).astype(int)\n",
        "\n",
        "        clf_ridge = Ridge(alpha=1.0)\n",
        "        clf_ridge.fit(K_train, y_train_binary)\n",
        "        y_pred_ridge = clf_ridge.predict(K_test)\n",
        "        y_pred_ridge_binary = np.clip(y_pred_ridge, 0, 1)  # обрезаем значения меньше 0 и больше 1\n",
        "        y_pred_ridge_binary = (y_pred_ridge_binary >= 0.5).astype(int) \n",
        "        acc_ridge = 0\n",
        "        acc_ridge = accuracy_score(y_test_binary, y_pred_ridge_binary)\n",
        "        \n",
        "        end = time.time()\n",
        "        results.append({\n",
        "            \"dataset_name\": dataset_name, \n",
        "            \"kernel\": gk.__class__.__name__,\n",
        "            \"SVM accuracy\": round(acc_svm * 100, 2),\n",
        "            \"Ridge accuracy\": round(acc_ridge * 100, 2),\n",
        "            \"time\": round(end - start, 2)\n",
        "        })\n",
        "        \n",
        "    \n",
        "    results_df = pd.DataFrame(results)\n",
        "\n",
        "    return results_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "10710a85",
      "metadata": {},
      "outputs": [],
      "source": [
        "easy_small = kernel_trick_(\"easy_small\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "562e17db",
      "metadata": {},
      "outputs": [],
      "source": [
        "hard_small = kernel_trick_(\"hard_small\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "11192783",
      "metadata": {},
      "outputs": [],
      "source": [
        "# easy = kernel_trick_(\"easy\")\n",
        "# hard = kernel_trick_(\"hard\")\n",
        "\n",
        "# При выполнении кода в текущей ячейке или предыдущей ячейке ядро аварийно завершило работу. \n",
        "# Проверьте код в ячейках, чтобы определить возможную причину сбоя. \n",
        "# Щелкните здесь, чтобы получить дополнительные сведения. \n",
        "# Подробнее см. в журнале Jupyter.\n",
        "# \"Системе не хватает программной памяти\"\n",
        "\n",
        "# поэтому без этих двух датасетов:("
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "4f39b6df",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>dataset_name</th>\n",
              "      <th>kernel</th>\n",
              "      <th>SVM accuracy</th>\n",
              "      <th>Ridge accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>easy_small</td>\n",
              "      <td>ShortestPath</td>\n",
              "      <td>100.00</td>\n",
              "      <td>100.00</td>\n",
              "      <td>2.23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>easy_small</td>\n",
              "      <td>GraphletSampling</td>\n",
              "      <td>41.94</td>\n",
              "      <td>67.74</td>\n",
              "      <td>94.30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>easy_small</td>\n",
              "      <td>WeisfeilerLehman</td>\n",
              "      <td>51.61</td>\n",
              "      <td>70.97</td>\n",
              "      <td>0.24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>easy_small</td>\n",
              "      <td>NeighborhoodHash</td>\n",
              "      <td>96.77</td>\n",
              "      <td>90.32</td>\n",
              "      <td>0.84</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>easy_small</td>\n",
              "      <td>PyramidMatch</td>\n",
              "      <td>51.61</td>\n",
              "      <td>70.97</td>\n",
              "      <td>1.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>easy_small</td>\n",
              "      <td>OddSth</td>\n",
              "      <td>77.42</td>\n",
              "      <td>93.55</td>\n",
              "      <td>14.17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>easy_small</td>\n",
              "      <td>CoreFramework</td>\n",
              "      <td>100.00</td>\n",
              "      <td>100.00</td>\n",
              "      <td>16.66</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>easy_small</td>\n",
              "      <td>Propagation</td>\n",
              "      <td>90.32</td>\n",
              "      <td>93.55</td>\n",
              "      <td>0.90</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>easy_small</td>\n",
              "      <td>RandomWalk</td>\n",
              "      <td>19.35</td>\n",
              "      <td>48.39</td>\n",
              "      <td>141.43</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>easy_small</td>\n",
              "      <td>SvmTheta</td>\n",
              "      <td>29.03</td>\n",
              "      <td>70.97</td>\n",
              "      <td>1.44</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>easy_small</td>\n",
              "      <td>VertexHistogram</td>\n",
              "      <td>29.03</td>\n",
              "      <td>70.97</td>\n",
              "      <td>0.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>hard_small</td>\n",
              "      <td>ShortestPath</td>\n",
              "      <td>69.23</td>\n",
              "      <td>69.23</td>\n",
              "      <td>1.12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>hard_small</td>\n",
              "      <td>GraphletSampling</td>\n",
              "      <td>38.46</td>\n",
              "      <td>65.38</td>\n",
              "      <td>13.79</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>hard_small</td>\n",
              "      <td>WeisfeilerLehman</td>\n",
              "      <td>23.08</td>\n",
              "      <td>65.38</td>\n",
              "      <td>0.23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>hard_small</td>\n",
              "      <td>NeighborhoodHash</td>\n",
              "      <td>76.92</td>\n",
              "      <td>65.38</td>\n",
              "      <td>0.79</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>hard_small</td>\n",
              "      <td>PyramidMatch</td>\n",
              "      <td>23.08</td>\n",
              "      <td>65.38</td>\n",
              "      <td>1.02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>hard_small</td>\n",
              "      <td>OddSth</td>\n",
              "      <td>42.31</td>\n",
              "      <td>65.38</td>\n",
              "      <td>6.12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>hard_small</td>\n",
              "      <td>CoreFramework</td>\n",
              "      <td>69.23</td>\n",
              "      <td>69.23</td>\n",
              "      <td>6.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>hard_small</td>\n",
              "      <td>Propagation</td>\n",
              "      <td>53.85</td>\n",
              "      <td>69.23</td>\n",
              "      <td>1.41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>hard_small</td>\n",
              "      <td>RandomWalk</td>\n",
              "      <td>23.08</td>\n",
              "      <td>38.46</td>\n",
              "      <td>146.89</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>hard_small</td>\n",
              "      <td>SvmTheta</td>\n",
              "      <td>15.38</td>\n",
              "      <td>65.38</td>\n",
              "      <td>0.53</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>hard_small</td>\n",
              "      <td>VertexHistogram</td>\n",
              "      <td>15.38</td>\n",
              "      <td>65.38</td>\n",
              "      <td>0.02</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   dataset_name            kernel  SVM accuracy  Ridge accuracy    time\n",
              "0    easy_small      ShortestPath        100.00          100.00    2.23\n",
              "1    easy_small  GraphletSampling         41.94           67.74   94.30\n",
              "2    easy_small  WeisfeilerLehman         51.61           70.97    0.24\n",
              "3    easy_small  NeighborhoodHash         96.77           90.32    0.84\n",
              "4    easy_small      PyramidMatch         51.61           70.97    1.01\n",
              "5    easy_small            OddSth         77.42           93.55   14.17\n",
              "6    easy_small     CoreFramework        100.00          100.00   16.66\n",
              "7    easy_small       Propagation         90.32           93.55    0.90\n",
              "8    easy_small        RandomWalk         19.35           48.39  141.43\n",
              "9    easy_small          SvmTheta         29.03           70.97    1.44\n",
              "10   easy_small   VertexHistogram         29.03           70.97    0.01\n",
              "11   hard_small      ShortestPath         69.23           69.23    1.12\n",
              "12   hard_small  GraphletSampling         38.46           65.38   13.79\n",
              "13   hard_small  WeisfeilerLehman         23.08           65.38    0.23\n",
              "14   hard_small  NeighborhoodHash         76.92           65.38    0.79\n",
              "15   hard_small      PyramidMatch         23.08           65.38    1.02\n",
              "16   hard_small            OddSth         42.31           65.38    6.12\n",
              "17   hard_small     CoreFramework         69.23           69.23    6.01\n",
              "18   hard_small       Propagation         53.85           69.23    1.41\n",
              "19   hard_small        RandomWalk         23.08           38.46  146.89\n",
              "20   hard_small          SvmTheta         15.38           65.38    0.53\n",
              "21   hard_small   VertexHistogram         15.38           65.38    0.02"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.concat([easy_small, hard_small], ignore_index=True)\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "bd3b7d68",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>dataset_name</th>\n",
              "      <th>kernel</th>\n",
              "      <th>SVM accuracy</th>\n",
              "      <th>Ridge accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>easy_small</td>\n",
              "      <td>ShortestPath</td>\n",
              "      <td>100.00</td>\n",
              "      <td>100.00</td>\n",
              "      <td>2.23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>easy_small</td>\n",
              "      <td>GraphletSampling</td>\n",
              "      <td>41.94</td>\n",
              "      <td>67.74</td>\n",
              "      <td>94.30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>easy_small</td>\n",
              "      <td>WeisfeilerLehman</td>\n",
              "      <td>51.61</td>\n",
              "      <td>70.97</td>\n",
              "      <td>0.24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>easy_small</td>\n",
              "      <td>NeighborhoodHash</td>\n",
              "      <td>96.77</td>\n",
              "      <td>90.32</td>\n",
              "      <td>0.84</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>easy_small</td>\n",
              "      <td>PyramidMatch</td>\n",
              "      <td>51.61</td>\n",
              "      <td>70.97</td>\n",
              "      <td>1.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>easy_small</td>\n",
              "      <td>OddSth</td>\n",
              "      <td>77.42</td>\n",
              "      <td>93.55</td>\n",
              "      <td>14.17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>easy_small</td>\n",
              "      <td>CoreFramework</td>\n",
              "      <td>100.00</td>\n",
              "      <td>100.00</td>\n",
              "      <td>16.66</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>easy_small</td>\n",
              "      <td>Propagation</td>\n",
              "      <td>90.32</td>\n",
              "      <td>93.55</td>\n",
              "      <td>0.90</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>easy_small</td>\n",
              "      <td>RandomWalk</td>\n",
              "      <td>19.35</td>\n",
              "      <td>48.39</td>\n",
              "      <td>141.43</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>easy_small</td>\n",
              "      <td>SvmTheta</td>\n",
              "      <td>29.03</td>\n",
              "      <td>70.97</td>\n",
              "      <td>1.44</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>easy_small</td>\n",
              "      <td>VertexHistogram</td>\n",
              "      <td>29.03</td>\n",
              "      <td>70.97</td>\n",
              "      <td>0.01</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   dataset_name            kernel  SVM accuracy  Ridge accuracy    time\n",
              "0    easy_small      ShortestPath        100.00          100.00    2.23\n",
              "1    easy_small  GraphletSampling         41.94           67.74   94.30\n",
              "2    easy_small  WeisfeilerLehman         51.61           70.97    0.24\n",
              "3    easy_small  NeighborhoodHash         96.77           90.32    0.84\n",
              "4    easy_small      PyramidMatch         51.61           70.97    1.01\n",
              "5    easy_small            OddSth         77.42           93.55   14.17\n",
              "6    easy_small     CoreFramework        100.00          100.00   16.66\n",
              "7    easy_small       Propagation         90.32           93.55    0.90\n",
              "8    easy_small        RandomWalk         19.35           48.39  141.43\n",
              "9    easy_small          SvmTheta         29.03           70.97    1.44\n",
              "10   easy_small   VertexHistogram         29.03           70.97    0.01"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "easy_small"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "58ae9634",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>dataset_name</th>\n",
              "      <th>kernel</th>\n",
              "      <th>SVM accuracy</th>\n",
              "      <th>Ridge accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>hard_small</td>\n",
              "      <td>ShortestPath</td>\n",
              "      <td>69.23</td>\n",
              "      <td>69.23</td>\n",
              "      <td>1.12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>hard_small</td>\n",
              "      <td>GraphletSampling</td>\n",
              "      <td>38.46</td>\n",
              "      <td>65.38</td>\n",
              "      <td>13.79</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>hard_small</td>\n",
              "      <td>WeisfeilerLehman</td>\n",
              "      <td>23.08</td>\n",
              "      <td>65.38</td>\n",
              "      <td>0.23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>hard_small</td>\n",
              "      <td>NeighborhoodHash</td>\n",
              "      <td>76.92</td>\n",
              "      <td>65.38</td>\n",
              "      <td>0.79</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>hard_small</td>\n",
              "      <td>PyramidMatch</td>\n",
              "      <td>23.08</td>\n",
              "      <td>65.38</td>\n",
              "      <td>1.02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>hard_small</td>\n",
              "      <td>OddSth</td>\n",
              "      <td>42.31</td>\n",
              "      <td>65.38</td>\n",
              "      <td>6.12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>hard_small</td>\n",
              "      <td>CoreFramework</td>\n",
              "      <td>69.23</td>\n",
              "      <td>69.23</td>\n",
              "      <td>6.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>hard_small</td>\n",
              "      <td>Propagation</td>\n",
              "      <td>53.85</td>\n",
              "      <td>69.23</td>\n",
              "      <td>1.41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>hard_small</td>\n",
              "      <td>RandomWalk</td>\n",
              "      <td>23.08</td>\n",
              "      <td>38.46</td>\n",
              "      <td>146.89</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>hard_small</td>\n",
              "      <td>SvmTheta</td>\n",
              "      <td>15.38</td>\n",
              "      <td>65.38</td>\n",
              "      <td>0.53</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>hard_small</td>\n",
              "      <td>VertexHistogram</td>\n",
              "      <td>15.38</td>\n",
              "      <td>65.38</td>\n",
              "      <td>0.02</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   dataset_name            kernel  SVM accuracy  Ridge accuracy    time\n",
              "0    hard_small      ShortestPath         69.23           69.23    1.12\n",
              "1    hard_small  GraphletSampling         38.46           65.38   13.79\n",
              "2    hard_small  WeisfeilerLehman         23.08           65.38    0.23\n",
              "3    hard_small  NeighborhoodHash         76.92           65.38    0.79\n",
              "4    hard_small      PyramidMatch         23.08           65.38    1.02\n",
              "5    hard_small            OddSth         42.31           65.38    6.12\n",
              "6    hard_small     CoreFramework         69.23           69.23    6.01\n",
              "7    hard_small       Propagation         53.85           69.23    1.41\n",
              "8    hard_small        RandomWalk         23.08           38.46  146.89\n",
              "9    hard_small          SvmTheta         15.38           65.38    0.53\n",
              "10   hard_small   VertexHistogram         15.38           65.38    0.02"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "hard_small "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "de4eda15",
      "metadata": {},
      "outputs": [],
      "source": [
        "# подберем лучшее ядро для всех случаев \n",
        "def select_best_kernel(df):\n",
        "    df['SVM accuracy'] = pd.to_numeric(df['SVM accuracy'])\n",
        "    df['Ridge accuracy'] = pd.to_numeric(df['Ridge accuracy'])\n",
        "    \n",
        "    df = df.pivot_table(index='kernel', columns='dataset_name', values=['SVM accuracy', 'Ridge accuracy', 'time'], aggfunc='first')\n",
        "    df.columns = [f\"{col[0]} {col[1]}\" for col in df.columns]\n",
        "    df.reset_index(inplace=True)\n",
        "    \n",
        "    accuracy_columns = df.filter(like='accuracy').columns\n",
        "    df['Total accuracy'] = df[accuracy_columns].sum(axis=1)\n",
        "    best_df = df.loc[df['Total accuracy'].idxmax()]\n",
        "\n",
        "    return best_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "0efbbb08",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'CoreFramework'"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "best_kernels_df = select_best_kernel(df)\n",
        "best_kernels_df['kernel']"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "af777ee5",
      "metadata": {},
      "source": [
        "## Дополнительно \n",
        " - поэкспериментируйте с kernel construction на основе kernels из библиотеки и попробуйте предложить свой kernel, который работает лучше\n",
        "\n",
        "Попробуем композиции различных ядер"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "015df08d",
      "metadata": {},
      "outputs": [],
      "source": [
        "class SumKernel:\n",
        "    # преобразуем каждый граф с помощью каждого ядра и суммируем результаты\n",
        "    def __init__(self, kernels):\n",
        "        self.kernels = kernels\n",
        "\n",
        "    def fit_transform(self, graphs):\n",
        "        kernels_results = [kernel.fit_transform(graphs) for kernel in self.kernels]\n",
        "        return np.sum(kernels_results, axis=0) \n",
        "\n",
        "    def transform(self, graphs):\n",
        "        kernels_results = [kernel.transform(graphs) for kernel in self.kernels]\n",
        "        return np.sum(kernels_results, axis=0)\n",
        "    \n",
        "class ProductKernel:\n",
        "    # преобразуем каждый граф с помощью каждого ядра и перемножаем результаты и еще умножаем на константу\n",
        "    def __init__(self, kernels, const):\n",
        "        self.kernels = kernels\n",
        "        self.const = const \n",
        "\n",
        "    def fit_transform(self, graphs):\n",
        "        kernels_results = [kernel.fit_transform(graphs) for kernel in self.kernels]\n",
        "        return self.const*np.prod(kernels_results, axis=0)  \n",
        "\n",
        "    def transform(self, graphs):\n",
        "        kernels_results = [kernel.transform(graphs) for kernel in self.kernels]\n",
        "        return self.const*np.prod(kernels_results, axis=0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "873a373e",
      "metadata": {},
      "outputs": [],
      "source": [
        "def custom_kernel_construction(dataset_name):\n",
        "    # делаем аналогично тому, что выше, но с кастомными ядрами\n",
        "    A_train, X_train, y_train, A_test, X_test, y_test = load_datasets_with_graphs(dataset_name)\n",
        "\n",
        "\n",
        "    G_tr = [create_networkx_graph(a, x) for a, x in zip(A_train, X_train)]\n",
        "    G_te = [create_networkx_graph(a, x) for a, x in zip(A_test, X_test)]\n",
        "\n",
        "    G_train = list(graph_from_networkx(G_tr, node_labels_tag='features'))\n",
        "    G_test = list(graph_from_networkx(G_te, node_labels_tag='features'))\n",
        "\n",
        "    y_train = np.argmax(y_train, axis=-1)\n",
        "    y_test = np.argmax(y_test, axis=-1)\n",
        "\n",
        "    kernels = [\n",
        "        SumKernel([ShortestPath(normalize=True), CoreFramework(normalize=True), NeighborhoodHash(random_state=10, normalize=True)]), \n",
        "        ProductKernel([ShortestPath(normalize=True), CoreFramework(normalize=True)], 3)\n",
        "    ]\n",
        "\n",
        "    results = []\n",
        "\n",
        "    for gk in kernels:\n",
        "        start = time.time()\n",
        "        \n",
        "        K_train = gk.fit_transform(G_train)\n",
        "        K_test = gk.transform(G_test)\n",
        "        \n",
        "        K_train = np.nan_to_num(K_train, nan=0.5)\n",
        "        K_test = np.nan_to_num(K_test, nan=0.5)\n",
        "        \n",
        "        clf_svm = SVC(kernel='precomputed', C=1)\n",
        "        clf_svm.fit(K_train, y_train)\n",
        "        y_pred_svm = clf_svm.predict(K_test)\n",
        "        acc_svm = accuracy_score(y_test, y_pred_svm)\n",
        "        \n",
        "        y_train_binary = (y_train == 1).astype(int)\n",
        "        y_test_binary = (y_test == 1).astype(int)\n",
        "\n",
        "        clf_ridge = Ridge(alpha=1.0)\n",
        "        clf_ridge.fit(K_train, y_train_binary)\n",
        "        y_pred_ridge = clf_ridge.predict(K_test)\n",
        "        y_pred_ridge_binary = np.clip(y_pred_ridge, 0, 1)\n",
        "        y_pred_ridge_binary = (y_pred_ridge_binary >= 0.5).astype(int)\n",
        "        acc_ridge = accuracy_score(y_test_binary, y_pred_ridge_binary)\n",
        "        \n",
        "        end = time.time()\n",
        "        results.append({\n",
        "            \"dataset_name\": dataset_name,\n",
        "            \"kernel\": gk.__class__.__name__,\n",
        "            \"SVM accuracy\": round(acc_svm * 100, 2),\n",
        "            \"Ridge accuracy\": round(acc_ridge * 100, 2),\n",
        "            \"time\": round(end - start, 2)\n",
        "        })\n",
        "\n",
        "    results_df = pd.DataFrame(results)\n",
        "    return results_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "b5044cc6",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>dataset_name</th>\n",
              "      <th>kernel</th>\n",
              "      <th>SVM accuracy</th>\n",
              "      <th>Ridge accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>easy_small</td>\n",
              "      <td>SumKernel</td>\n",
              "      <td>100.00</td>\n",
              "      <td>96.77</td>\n",
              "      <td>19.82</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>easy_small</td>\n",
              "      <td>ProductKernel</td>\n",
              "      <td>100.00</td>\n",
              "      <td>100.00</td>\n",
              "      <td>18.77</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>hard_small</td>\n",
              "      <td>SumKernel</td>\n",
              "      <td>76.92</td>\n",
              "      <td>84.62</td>\n",
              "      <td>7.56</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>hard_small</td>\n",
              "      <td>ProductKernel</td>\n",
              "      <td>80.77</td>\n",
              "      <td>76.92</td>\n",
              "      <td>6.56</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  dataset_name         kernel  SVM accuracy  Ridge accuracy   time\n",
              "0   easy_small      SumKernel        100.00           96.77  19.82\n",
              "1   easy_small  ProductKernel        100.00          100.00  18.77\n",
              "2   hard_small      SumKernel         76.92           84.62   7.56\n",
              "3   hard_small  ProductKernel         80.77           76.92   6.56"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_custom_k_hard = custom_kernel_construction(\"hard_small\")\n",
        "df_custom_k_easy = custom_kernel_construction(\"easy_small\")\n",
        "df_custom_k = pd.concat([df_custom_k_easy, df_custom_k_hard], ignore_index=True)\n",
        "df_custom_k"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cec9a0ff",
      "metadata": {},
      "source": [
        "- на датасете hard_small получили лучше результаты, чем те, которые были при примение различных ядер (лучшие были 76,92 - svm и 69,23 - ridge reg на разных ядрах, а сейчас 80.77 - svm и 84.62 - ridge reg)\n",
        "- на easy_small и так получали 100 и сейчас получили 100"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "107ac0a0-4451-4ce3-a280-da2beae5a358",
      "metadata": {
        "id": "107ac0a0-4451-4ce3-a280-da2beae5a358"
      },
      "source": [
        "# Задание 3.\n",
        "\n",
        "Подберите несколько датасетов с большим количеством предикторов (>20) из UCI репозитория или любого другого (классификация и/или регрессия). Реализуйте gaussian process (можно взять готовый но скорее всего его все равно придется модфицировать) для подбора гиперпараметров random forest (или какого либо бустинга) (смотрите лекцию 3). Сравните скорость с random search (попытайтесь презойти).\n",
        "\n",
        "**Дополнительно**: поэксперементируйте с критериями подбора следующей точки (лекция 3) и ядрами, а также с самими критериями качества (есть ли отличие в эффективности gaussian process для разных критериев)\n",
        "\n",
        "P. S.: в этом задании оцениваться будет прежде всего правильность реализации, а не скорость, т.к. сделать быстрее рандома (в виду требуемых доп вычислений) может быть сложно и это зависит от датасета, но нужно попытаться реализовать как можно эффективнее."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c810e089",
      "metadata": {},
      "source": [
        "Попробуем несколько датасетов:\n",
        "- breast cancer (один из самых популярных датасетов uci) c 30 features\n",
        "- Predict Students' Dropout and Academic Success: 36 features\n",
        "- Default of Credit Card Clients: 23 features\n",
        "- Optical Recognition of Handwritten Digits: 64 features\n",
        "- Connectionist Bench (Sonar, Mines vs. Rocks): 60 features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "bd2f5844",
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_credit_card_clients():\n",
        "    default_of_credit_card_clients = fetch_ucirepo(id=350) \n",
        "    X = default_of_credit_card_clients.data.features \n",
        "    y = default_of_credit_card_clients.data.targets \n",
        "    data = SimpleNamespace(data=X, target=y)\n",
        "    return data\n",
        "\n",
        "def load_students():\n",
        "    predict_students_dropout_and_academic_success = fetch_ucirepo(id=697)\n",
        "    X = predict_students_dropout_and_academic_success.data.features \n",
        "    y = predict_students_dropout_and_academic_success.data.targets \n",
        "    data = SimpleNamespace(data=X, target=y)\n",
        "    return data\n",
        "\n",
        "def load_mushrooms():\n",
        "    mushroom = fetch_ucirepo(id=73) \n",
        "    X = mushroom.data.features \n",
        "    for column in X.columns:\n",
        "        if X[column].dtype == 'object': \n",
        "            encoder = LabelEncoder()\n",
        "            X[column] = encoder.fit_transform(X[column])\n",
        "    y = mushroom.data.targets \n",
        "    y = y['poisonous'].map({'p': 1, 'e': 0})\n",
        "    data = SimpleNamespace(data=X, target=y)\n",
        "    return data\n",
        "\n",
        "def load_digits():\n",
        "    optical_recognition_of_handwritten_digits = fetch_ucirepo(id=80) \n",
        "    X = optical_recognition_of_handwritten_digits.data.features \n",
        "    y = optical_recognition_of_handwritten_digits.data.targets \n",
        "    data = SimpleNamespace(data=X, target=y)\n",
        "    return data\n",
        "\n",
        "def load_connectionist():\n",
        "    connectionist_bench_sonar_mines_vs_rocks = fetch_ucirepo(id=151)\n",
        "    X = connectionist_bench_sonar_mines_vs_rocks.data.features \n",
        "    y = connectionist_bench_sonar_mines_vs_rocks.data.targets \n",
        "    y = y['class'].map({'M': 1, 'R': 0})\n",
        "    data = SimpleNamespace(data=X, target=y)\n",
        "    return data\n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "86c36e00",
      "metadata": {},
      "outputs": [],
      "source": [
        "def objective_function(params, X_train, X_test, y_train, y_test, random_st=5):\n",
        "    n_estimators = int(params[0])\n",
        "    max_depth = int(params[1])\n",
        "    min_samples_split = int(params[2])\n",
        "    min_samples_leaf = int(params[3])\n",
        "\n",
        "    rf = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, min_samples_split=min_samples_split,\n",
        "                                min_samples_leaf=min_samples_leaf,\n",
        "                                random_state=random_st)  # random forest c текущими параметрами\n",
        "    rf.fit(X_train, y_train)\n",
        "\n",
        "    y_pred = rf.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "    return -accuracy  # минимизируем функцию (поэтому знак минус)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "395568f9",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Expected Improvement для gp\n",
        "def expected_improvement(x, gp, y_best):\n",
        "    # GP для точки x\n",
        "    mu, sigma = gp.predict([x], return_std=True)\n",
        "    if sigma == 0:\n",
        "        return 0\n",
        "    improvement = mu - y_best\n",
        "    Z = improvement / sigma\n",
        "    EI = improvement * norm.cdf(Z) + sigma * norm.pdf(Z)\n",
        "    return EI\n",
        "\n",
        "\n",
        "# ф-я для оптимизации гиперпараметров с помощью gp\n",
        "def optimize_gp(X_train, X_test, y_train, y_test, random_st=5, num_iter=10):\n",
        "    # начальные гиперпараметры (случайные)\n",
        "    param_space = np.array([[10, 50],  # n_estimators от 10 до 50\n",
        "                            [5, 20],  # max_depth от 5 до 20\n",
        "                            [2, 20],  # min_samples_split от 2 до 20\n",
        "                            [1, 20]])  # min_samples_leaf от 1 до 20\n",
        "\n",
        "    # начальные случайные точки для обучения GP\n",
        "    X_train_gp = np.array([[random.randint(10, 50),\n",
        "                            random.randint(5, 20),\n",
        "                            random.randint(2, 20),\n",
        "                            random.randint(1, 20)] for _ in range(num_iter)])\n",
        "\n",
        "    y_train_gp = np.array([objective_function(params, X_train, X_test, y_train, y_test,random_st=random_st) for params in X_train_gp])  # начальные оценки метрик\n",
        "\n",
        "    kernel = RBF(1.0, (1e-5, 1e1))  # kernel для GP\n",
        "    gp = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=10, random_state=random_st)\n",
        "    gp.fit(X_train_gp, y_train_gp)\n",
        "\n",
        "    # оптимизация гиперпараметров\n",
        "    for _ in range(5):\n",
        "        # выбор след точки для сэмплирования с помощью EI\n",
        "        next_params = None\n",
        "        max_ei = -np.inf\n",
        "\n",
        "        for _ in range(50):  # проверяем 50 точек\n",
        "            candidate = np.random.uniform(param_space[:, 0], param_space[:, 1])\n",
        "            ei = expected_improvement(candidate, gp, np.min(y_train_gp))\n",
        "            if ei > max_ei:\n",
        "                max_ei = ei\n",
        "                next_params = candidate\n",
        "\n",
        "        y_new = objective_function(next_params, X_train, X_test, y_train, y_test, random_st=random_st)\n",
        "        X_train_gp = np.vstack([X_train_gp, next_params])\n",
        "        y_train_gp = np.append(y_train_gp, y_new)\n",
        "\n",
        "        gp.fit(X_train_gp, y_train_gp)\n",
        "\n",
        "    best_params = X_train_gp[np.argmin(y_train_gp)]  # гиперпараметры с минимальной ошибкой\n",
        "    best_acc = -np.min(y_train_gp)\n",
        "    return best_params, best_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "13f15b00",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Random Search\n",
        "def random_search(X_train, X_test, y_train, y_test, random_st=5, num_iter=10):\n",
        "    best_acc = -np.inf\n",
        "    best_params = None\n",
        "    for _ in range(num_iter):\n",
        "        params = [random.randint(10, 50),\n",
        "                  random.randint(5, 20),\n",
        "                  random.randint(2, 20),\n",
        "                  random.randint(1, 20)]\n",
        "\n",
        "        accuracy = -objective_function(params, X_train, X_test, y_train, y_test, random_st=random_st)  # минимизируем \n",
        "\n",
        "        if accuracy > best_acc:\n",
        "            best_acc = accuracy\n",
        "            best_params = params\n",
        "\n",
        "    return best_params, best_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "28333a57",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Dataset</th>\n",
              "      <th>Best GP params</th>\n",
              "      <th>Best GP accuracy</th>\n",
              "      <th>GP time</th>\n",
              "      <th>Best Random Search params</th>\n",
              "      <th>Best Random Search accuracy</th>\n",
              "      <th>Random Search time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>breast_cancer</td>\n",
              "      <td>[25.00, 15.00, 3.00, 7.00]</td>\n",
              "      <td>0.973684</td>\n",
              "      <td>0.432448</td>\n",
              "      <td>[16, 19, 15, 15]</td>\n",
              "      <td>0.973684</td>\n",
              "      <td>0.241130</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>students</td>\n",
              "      <td>[42.04, 18.48, 3.47, 5.81]</td>\n",
              "      <td>0.811299</td>\n",
              "      <td>1.169018</td>\n",
              "      <td>[19, 8, 2, 8]</td>\n",
              "      <td>0.803390</td>\n",
              "      <td>0.676129</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>credit_card_clients</td>\n",
              "      <td>[47.52, 19.50, 20.00, 15.46]</td>\n",
              "      <td>0.821833</td>\n",
              "      <td>12.389363</td>\n",
              "      <td>[37, 15, 20, 18]</td>\n",
              "      <td>0.821500</td>\n",
              "      <td>9.298777</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>digits</td>\n",
              "      <td>[46.00, 19.00, 4.00, 3.00]</td>\n",
              "      <td>0.976868</td>\n",
              "      <td>1.821994</td>\n",
              "      <td>[28, 10, 6, 3]</td>\n",
              "      <td>0.971530</td>\n",
              "      <td>1.009588</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>connectionist</td>\n",
              "      <td>[47.89, 12.76, 3.43, 1.35]</td>\n",
              "      <td>0.880952</td>\n",
              "      <td>0.301829</td>\n",
              "      <td>[33, 12, 10, 2]</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.144626</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               Dataset                Best GP params  Best GP accuracy  \\\n",
              "0        breast_cancer    [25.00, 15.00, 3.00, 7.00]          0.973684   \n",
              "1             students    [42.04, 18.48, 3.47, 5.81]          0.811299   \n",
              "2  credit_card_clients  [47.52, 19.50, 20.00, 15.46]          0.821833   \n",
              "3               digits    [46.00, 19.00, 4.00, 3.00]          0.976868   \n",
              "4        connectionist    [47.89, 12.76, 3.43, 1.35]          0.880952   \n",
              "\n",
              "     GP time Best Random Search params  Best Random Search accuracy  \\\n",
              "0   0.432448          [16, 19, 15, 15]                     0.973684   \n",
              "1   1.169018             [19, 8, 2, 8]                     0.803390   \n",
              "2  12.389363          [37, 15, 20, 18]                     0.821500   \n",
              "3   1.821994            [28, 10, 6, 3]                     0.971530   \n",
              "4   0.301829           [33, 12, 10, 2]                     0.833333   \n",
              "\n",
              "   Random Search time  \n",
              "0            0.241130  \n",
              "1            0.676129  \n",
              "2            9.298777  \n",
              "3            1.009588  \n",
              "4            0.144626  "
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "datasets = {\n",
        "    'breast_cancer': load_breast_cancer(),\n",
        "    'students': load_students(),\n",
        "    \"credit_card_clients\": load_credit_card_clients(),\n",
        "    # \"mushrooms\": load_mushrooms(),\n",
        "    'digits': load_digits(),\n",
        "    'connectionist': load_connectionist()\n",
        "\n",
        "}\n",
        "\n",
        "def compare_gp_randomsearch(random_st=5):\n",
        "    results = []\n",
        "    time_results = []\n",
        "    \n",
        "    for dataset_name, dataset in datasets.items():\n",
        "        X = dataset.data\n",
        "        y = dataset.target\n",
        "\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=random_st)\n",
        "\n",
        "        # Gaussian Process\n",
        "        start_time = time.time()\n",
        "        best_params_gp, best_acc_gp = optimize_gp(X_train, X_test, y_train, y_test, random_st=random_st)\n",
        "        gp_time = time.time() - start_time\n",
        "\n",
        "        # Random Search\n",
        "        start_time = time.time()\n",
        "        best_params_random, best_acc_random = random_search(X_train, X_test, y_train, y_test, random_st=random_st)\n",
        "        random_time = time.time() - start_time\n",
        "        \n",
        "        results.append({\n",
        "            \"Dataset\": dataset_name,\n",
        "            \"Best GP params\": [f\"{best_param_gp:.2f}\" for best_param_gp in best_params_gp],\n",
        "            \"Best GP accuracy\": best_acc_gp,\n",
        "            \"GP time\": gp_time,\n",
        "            \"Best Random Search params\": best_params_random,\n",
        "            \"Best Random Search accuracy\": best_acc_random,\n",
        "            \"Random Search time\": random_time,\n",
        "            \n",
        "        })\n",
        "        \n",
        "    return pd.DataFrame(results)\n",
        "        \n",
        "compare_gp_randomsearch()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "97bec6b4",
      "metadata": {},
      "source": [
        "**Как видно, gp для подбора гиперпараметров работает дольше на 5/5 датасетов. Причем дольше в 1,5-2 раза (но как было описано в условии задания - это ожидаемый результат)**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ff4daa99",
      "metadata": {},
      "source": [
        "Чтобы сравнить accuracy двух методов, попробуем их применить при разных random_state и посмотреть в скольких случаях gp оказался лучше RS."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "1835ba0d",
      "metadata": {},
      "outputs": [],
      "source": [
        "def compare_gp_rs_ntimes(n_iter=10):\n",
        "    all_results = [] \n",
        "\n",
        "    for _ in range(n_iter):\n",
        "        random_st = random.randint(1, 100)\n",
        "        df = compare_gp_randomsearch(random_st=random_st) \n",
        "\n",
        "        new_data = []\n",
        "        \n",
        "        for _, row in df.iterrows():\n",
        "            dataset = row['Dataset']\n",
        "            best_gp_accuracy = row['Best GP accuracy']\n",
        "            best_rs_accuracy = row['Best Random Search accuracy']\n",
        "            \n",
        "            if best_gp_accuracy > best_rs_accuracy:  # gp лучше, чем rs\n",
        "                gp_better = 1\n",
        "                gp_eq_rs = 0\n",
        "                rs_better_gp = 0\n",
        "            elif best_gp_accuracy < best_rs_accuracy:  # gp хуже, чем rs\n",
        "                gp_better = 0\n",
        "                gp_eq_rs = 0\n",
        "                rs_better_gp = 1\n",
        "            else:  # значения равны\n",
        "                gp_better = 0\n",
        "                gp_eq_rs = 1\n",
        "                rs_better_gp = 0\n",
        "\n",
        "            new_data.append([dataset, gp_better, gp_eq_rs, rs_better_gp])\n",
        "\n",
        "        new_df = pd.DataFrame(new_data, columns=['Dataset', 'GP better than RS', 'GP acc = RS acc', 'RS better than GP'])\n",
        "        all_results.append(new_df)\n",
        "        \n",
        "    all_results_df = pd.concat(all_results, ignore_index=True)\n",
        "    \n",
        "    return all_results_df.groupby('Dataset', as_index=False).sum()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "5eecda7f",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Dataset</th>\n",
              "      <th>GP better than RS</th>\n",
              "      <th>GP acc = RS acc</th>\n",
              "      <th>RS better than GP</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>breast_cancer</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>connectionist</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>credit_card_clients</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>digits</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>students</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               Dataset  GP better than RS  GP acc = RS acc  RS better than GP\n",
              "0        breast_cancer                  5                4                  1\n",
              "1        connectionist                  8                1                  1\n",
              "2  credit_card_clients                  7                0                  3\n",
              "3               digits                  7                1                  2\n",
              "4             students                  9                1                  0"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "compare_gp_rs_ntimes()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "66ef9aee",
      "metadata": {},
      "source": [
        "Можно заметить, что в большинстве случаев gp демонстрирует лучшие результаты, чем rs (хоть gp и дольше), то есть на каждом датасете число случаев, когда accuracy у gp оказалась больше, чем у rs, сильно больше, чем число случаев, когда accuracy у rs оказалась больше, чем у gp"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "686c29ee",
      "metadata": {},
      "source": [
        "## Дополнительно\n",
        "- поэксперементируйте с критериями подбора следующей точки (лекция 3) и ядрами, а также с самими критериями качества (есть ли отличие в эффективности gaussian process для разных критериев)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1b82e07c",
      "metadata": {},
      "source": [
        "Попробуем добавить Probability of Improvement (PI), Upper Confidence Bound (UCB) из 3 лекции и три ядра RBF, Matern и Constant (его комбинацию с Matern и RBF)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "e7fb2d1a",
      "metadata": {},
      "outputs": [],
      "source": [
        "def probability_of_improvement(x, gp, y_best):\n",
        "    mu, sigma = gp.predict([x], return_std=True)\n",
        "    Z = (mu - y_best) / sigma\n",
        "    PI = norm.cdf(Z)\n",
        "    return PI\n",
        "\n",
        "def upper_confidence_bound(x, gp, k=2.0):\n",
        "    mu, sigma = gp.predict([x], return_std=True)\n",
        "    UCB = mu + k * sigma\n",
        "    return UCB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "557d0abe",
      "metadata": {},
      "outputs": [],
      "source": [
        "kernels_d = {\n",
        "    'RBF':  RBF(1.0, (1e-5, 1e1)),\n",
        "    'Matern': Matern(length_scale=1.0, nu=2.5, length_scale_bounds=(1e-5, 1e1)),\n",
        "    'ConstRBF': ConstantKernel(2.0, (1e-5, 1e1)) + RBF(1.0, (1e-5, 1e1)),\n",
        "    'ConstMatern': ConstantKernel(2.0, (1e-5, 1e1)) + Matern(length_scale=1.0, nu=2.5, length_scale_bounds=(1e-5, 1e1)),\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "e0d42f1b",
      "metadata": {},
      "outputs": [],
      "source": [
        "def optimize_gp_additional(X_train, X_test, y_train, y_test, kernel_type='RBF', ac_function='EI', random_st=5, num_iter=10):\n",
        "    param_space = np.array([[10, 50], [5, 20], [2, 20], [1, 20]])\n",
        "    \n",
        "    # начальные случайные точки для обучения GP\n",
        "    X_train_gp = np.array([[random.randint(10, 50),\n",
        "                            random.randint(5, 20),\n",
        "                            random.randint(2, 20),\n",
        "                            random.randint(1, 20)] for _ in range(num_iter)])\n",
        "\n",
        "    y_train_gp = np.array([objective_function(params, X_train, X_test, y_train, y_test,random_st=random_st) for params in X_train_gp])\n",
        "    \n",
        "    kernel = kernels_d[kernel_type]\n",
        "    \n",
        "    gp = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=10, random_state=random_st)\n",
        "    gp.fit(X_train_gp, y_train_gp)\n",
        "\n",
        "    for _ in range(5):\n",
        "        next_params = None\n",
        "        max_ac = -np.inf\n",
        "\n",
        "        for _ in range(50): \n",
        "            candidate = np.random.uniform(param_space[:, 0], param_space[:, 1])\n",
        "\n",
        "            if ac_function == 'EI':\n",
        "                ac_value = expected_improvement(candidate, gp, np.min(y_train_gp))\n",
        "            elif ac_function == 'PI':\n",
        "                ac_value = probability_of_improvement(candidate, gp, np.min(y_train_gp))\n",
        "            elif ac_function == 'UCB':\n",
        "                ac_value = upper_confidence_bound(candidate, gp)\n",
        "\n",
        "            if ac_value > max_ac:\n",
        "                max_ac = ac_value\n",
        "                next_params = candidate\n",
        "\n",
        "        y_new = objective_function(next_params, X_train, X_test, y_train, y_test, random_st=random_st)\n",
        "        X_train_gp = np.vstack([X_train_gp, next_params])\n",
        "        y_train_gp = np.append(y_train_gp, y_new)\n",
        "\n",
        "        gp.fit(X_train_gp, y_train_gp)\n",
        "\n",
        "    best_params = X_train_gp[np.argmin(y_train_gp)] \n",
        "    best_acc = -np.min(y_train_gp)\n",
        "    return best_params, best_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "00dccd9a",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Dataset</th>\n",
              "      <th>Best GP accuracy</th>\n",
              "      <th>Best GP kernel</th>\n",
              "      <th>Best GP aquisition function</th>\n",
              "      <th>GP time</th>\n",
              "      <th>Best Random Search accuracy</th>\n",
              "      <th>Random Search time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>breast_cancer</td>\n",
              "      <td>0.982456</td>\n",
              "      <td>RBF</td>\n",
              "      <td>EI</td>\n",
              "      <td>0.588609</td>\n",
              "      <td>0.964912</td>\n",
              "      <td>0.383906</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>students</td>\n",
              "      <td>0.805650</td>\n",
              "      <td>RBF</td>\n",
              "      <td>EI</td>\n",
              "      <td>2.211132</td>\n",
              "      <td>0.801130</td>\n",
              "      <td>1.213934</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>digits</td>\n",
              "      <td>0.979537</td>\n",
              "      <td>ConstRBF</td>\n",
              "      <td>EI</td>\n",
              "      <td>3.045867</td>\n",
              "      <td>0.975089</td>\n",
              "      <td>2.117088</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>connectionist</td>\n",
              "      <td>0.880952</td>\n",
              "      <td>RBF</td>\n",
              "      <td>UCB</td>\n",
              "      <td>0.779022</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.276734</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         Dataset  Best GP accuracy Best GP kernel Best GP aquisition function  \\\n",
              "0  breast_cancer          0.982456            RBF                          EI   \n",
              "1       students          0.805650            RBF                          EI   \n",
              "2         digits          0.979537       ConstRBF                          EI   \n",
              "3  connectionist          0.880952            RBF                         UCB   \n",
              "\n",
              "    GP time  Best Random Search accuracy  Random Search time  \n",
              "0  0.588609                     0.964912            0.383906  \n",
              "1  2.211132                     0.801130            1.213934  \n",
              "2  3.045867                     0.975089            2.117088  \n",
              "3  0.779022                     0.833333            0.276734  "
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "datasets = {\n",
        "    'breast_cancer': load_breast_cancer(),\n",
        "    'students': load_students(),\n",
        "    # \"credit_card_clients\": load_credit_card_clients(), # очень долгий\n",
        "    # \"mushrooms\": load_mushrooms(),\n",
        "    'digits': load_digits(),\n",
        "    'connectionist': load_connectionist()\n",
        "\n",
        "}\n",
        "# GP и Random Search c разными ядрами\n",
        "def compare_gp_randomsearch_additional(random_st=5):\n",
        "    results = []\n",
        "    \n",
        "    for dataset_name, dataset in datasets.items():\n",
        "        X = dataset.data\n",
        "        y = dataset.target\n",
        "\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=random_st)\n",
        "\n",
        "        # Gaussian Process\n",
        "        best_kernel = None\n",
        "        best_ac_fun = None\n",
        "        best_acc_gp = 0\n",
        "        res_time_gp = 0\n",
        "        for kernel_type, _ in kernels_d.items():\n",
        "            for f in ['EI', 'UCB', 'PI']:\n",
        "                start_time = time.time()\n",
        "                best_params_gp, acc_gp = optimize_gp_additional(X_train, X_test, y_train, y_test, kernel_type=kernel_type, ac_function=f, random_st=random_st)\n",
        "                gp_time = time.time() - start_time\n",
        "                \n",
        "                if acc_gp > best_acc_gp:\n",
        "                    best_acc_gp = acc_gp\n",
        "                    best_kernel = kernel_type\n",
        "                    best_ac_fun = f\n",
        "                    res_time_gp = gp_time\n",
        "                    \n",
        "\n",
        "        # Random Search\n",
        "        start_time = time.time()\n",
        "        best_params_random, best_acc_random = random_search(X_train, X_test, y_train, y_test, random_st=random_st)\n",
        "        random_time = time.time() - start_time\n",
        "        \n",
        "        results.append({\n",
        "            \"Dataset\": dataset_name,\n",
        "            \"Best GP accuracy\": best_acc_gp,\n",
        "            \"Best GP kernel\": best_kernel,\n",
        "            \"Best GP aquisition function\": best_ac_fun,\n",
        "            \"GP time\": res_time_gp,\n",
        "            \"Best Random Search accuracy\": best_acc_random,\n",
        "            \"Random Search time\": random_time,\n",
        "        })\n",
        "        \n",
        "    return pd.DataFrame(results)\n",
        "\n",
        "compare_gp_randomsearch_additional()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "76a99cb6",
      "metadata": {},
      "source": [
        " Теперь можно увидеть, что на всех датасетах GP показывает лучшую accuracy, чем RS (но на несколько сотых, а где-то  даже тысячных )"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
